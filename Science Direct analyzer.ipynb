{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/edenshrian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/edenshrian/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "import re\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import heapq\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('disable-infobars')\n",
    "chrome_options.add_argument('--disable-notifications')\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "chrome_options.add_argument('--disable-popup-blocking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sceince_direct_text_extractor:\n",
    "    \n",
    "    def __init__(self,key_word):\n",
    "        \n",
    "        self.key_word = key_word\n",
    "        self.urls = []\n",
    "        self.urls_to_drop = []\n",
    "        self.text_dict = {}\n",
    "    \n",
    "    def text_extractor(self):\n",
    "        \n",
    "        self.urls = sceince_direct_text_extractor.get_urls(self.key_word)\n",
    "        self.urls_to_drop , self.text_dict = sceince_direct_text_extractor.get_dict_of_abstract_text(self.urls)\n",
    "        \n",
    "        return \n",
    "                \n",
    "    def get_urls(key_word):\n",
    "\n",
    "        WEB_DRIVER_PATH = '/Users/edenshrian/Desktop/Documents/Eden Shrian/Eden/Chrome Driver/chromedriver'\n",
    "        url = \"https://www.sciencedirect.com/\"\n",
    "        driver = webdriver.Chrome(executable_path= WEB_DRIVER_PATH, options=chrome_options)\n",
    "        driver.get(url)\n",
    "        driver.maximize_window()\n",
    "        driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div[2]/div[1]/div/div/div/div/div/form/div/div[1]/div/div[1]/div/div/input\").send_keys(key_word)\n",
    "        driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div[2]/div[1]/div/div/div/div/div/form/div/div[1]/div/div[1]/div/div/input\").send_keys(Keys.RETURN)\n",
    "        time.sleep(2.0)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2.0)\n",
    "        index_of_num_3 = 2\n",
    "        max_search_in_web = 25\n",
    "        list_for_iteration = np.delete(np.arange(1,max_search_in_web+2),[index_of_num_3])\n",
    "        urls = [driver.find_element_by_xpath(f\"/html/body/div[1]/div/div/div/div[1]/div/div/section/div/div[2]/main/div[1]/div[2]/div[2]/div/ol/li[{num}]/div/div/h2/span/a\").get_attribute(\"href\") for num in list_for_iteration]\n",
    "        driver.close()\n",
    "\n",
    "        return urls\n",
    "    \n",
    "    def get_unique_examples():\n",
    "        \n",
    "        path = \"/Users/edenshrian/Desktop/Documents/Eden Shrian/Eden/Projects/Text Summary/urls.csv\"\n",
    "        df_urls = pd.read_csv(path)\n",
    "        unique_examples = list(set(list(df_urls['URLS'].values)))\n",
    "\n",
    "        return unique_examples\n",
    "\n",
    "    def parse_page_text(url):\n",
    "\n",
    "        WEB_DRIVER_PATH = '/Users/edenshrian/Desktop/Documents/Eden Shrian/Eden/Chrome Driver/chromedriver'\n",
    "        driver = webdriver.Chrome(executable_path= WEB_DRIVER_PATH, options=chrome_options)\n",
    "        driver.get(url)\n",
    "        driver.maximize_window()\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        title = driver.title\n",
    "        title = title.replace(\"-\",\"\")\n",
    "        title = title.replace(\"ScienceDirect\",\"\")\n",
    "        unique_examples = sceince_direct_text_extractor.get_unique_examples()\n",
    "\n",
    "        for example in unique_examples:\n",
    "            try:\n",
    "                text = driver.find_element_by_xpath(example).text\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        driver.close()\n",
    "\n",
    "        return title,text\n",
    "\n",
    "    def get_dict_of_abstract_text(urls):\n",
    "\n",
    "        specialChars = '!#$%^&*<>/•'\n",
    "        dictionary = {}\n",
    "        urls_to_drop = []\n",
    "        for url in urls:\n",
    "            try:\n",
    "                title,text = sceince_direct_text_extractor.parse_page_text(url)\n",
    "                for char in specialChars:\n",
    "                    text = text.replace(char,'')\n",
    "                dictionary[title] = text.replace(\"\\n\",\"\")\n",
    "            except:\n",
    "                urls_to_drop = url\n",
    "\n",
    "        return urls_to_drop,dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class summarize_sceince_direct_abstract(sceince_direct_text_extractor):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "        self.key_word = 0\n",
    "        self.num_of_sentences = 0\n",
    "        self.summary = 0\n",
    "        self.text_dict = {}\n",
    "        self.urls = []\n",
    "        \n",
    "    def get_summary(self,key_word,num_of_sentences):\n",
    "        \n",
    "        self.key_word = key_word\n",
    "        self.num_of_sentences = num_of_sentences\n",
    "        self.urls , self.text_dict , self.summary = summarize_sceince_direct_abstract.summarize_info_from_sceince_direct(self.key_word,\n",
    "                                                                                                             self.num_of_sentences)\n",
    "        return self.summary\n",
    "\n",
    "    def create_one_long_text(key_word):\n",
    "    \n",
    "        SD_text = sceince_direct_text_extractor(key_word)\n",
    "        SD_text.text_extractor()\n",
    "        long_text = \"\".join(list(SD_text.text_dict.values()))\n",
    "        text_dict = SD_text.text_dict\n",
    "        urls = SD_text.urls\n",
    "\n",
    "        return urls,text_dict,long_text\n",
    "\n",
    "    def tokenize_words_to_flat_list(long_text):\n",
    "\n",
    "        text_tokenize = sent_tokenize(long_text)\n",
    "        words = [word_tokenize(sent_token) for sent_token in text_tokenize] \n",
    "        flat_word_list = [item for sublist in words for item in sublist]\n",
    "\n",
    "        return text_tokenize,flat_word_list\n",
    "\n",
    "    def create_freq_dict(flat_word_list):\n",
    "\n",
    "        freq = {}\n",
    "        for word in flat_word_list:\n",
    "            if word not in stopwords and word.isalpha():\n",
    "                if word not in freq.keys():\n",
    "                    freq[word]  = 1\n",
    "                else:\n",
    "                    freq[word] +=1\n",
    "\n",
    "        return freq\n",
    "\n",
    "    def calculate_freq_in_dict(freq_dict):\n",
    "\n",
    "        max_freq = max(freq_dict.values())\n",
    "        for word in freq_dict.keys():\n",
    "            freq_dict[word] = (freq_dict[word]/max_freq)\n",
    "\n",
    "        return freq_dict\n",
    "\n",
    "    def calculate_sentence_score(text_tokenize,flat_word_list,freq_dict):\n",
    "\n",
    "        sentence_score = {}\n",
    "        for sent_token in text_tokenize:\n",
    "            for word in flat_word_list:\n",
    "                if word.lower() in freq_dict.keys():\n",
    "                    if sent_token not in sentence_score.keys():\n",
    "                        sentence_score[sent_token] = freq_dict[word]\n",
    "                    else:\n",
    "                        sentence_score[sent_token] += freq_dict[word]\n",
    "\n",
    "        return sentence_score\n",
    "\n",
    "    def get_summary_text(sentence_score,num_of_sentences):\n",
    "\n",
    "        summary_sentences = heapq.nlargest(num_of_sentences,\n",
    "                                          sentence_score,\n",
    "                                          key = sentence_score.get)\n",
    "\n",
    "        summary = ' '.join(summary_sentences)\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def summarize_info_from_sceince_direct(key_word,num_of_sentences):\n",
    "\n",
    "        urls,text_dict,long_text = summarize_sceince_direct_abstract.create_one_long_text(key_word)\n",
    "        text_tokenize,flat_word_list = summarize_sceince_direct_abstract.tokenize_words_to_flat_list(long_text)\n",
    "        freq_dict = summarize_sceince_direct_abstract.create_freq_dict(flat_word_list)\n",
    "        sentence_score = summarize_sceince_direct_abstract.calculate_sentence_score(text_tokenize,flat_word_list,freq_dict)\n",
    "        summary = summarize_sceince_direct_abstract.get_summary_text(sentence_score,num_of_sentences)\n",
    "\n",
    "        return urls,text_dict,summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summarize = summarize_sceince_direct_abstract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary1 = Summarize.get_summary(\"Deep Learning for stock predictions\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stock market prediction has been a classical yet challenging problem, with the attention from both economists and computer scientists. With the purpose of building an effective prediction model, both linear and machine learning tools have been explored for the past couple of decades. Lately, deep learning models have been introduced as new frontiers for this topic and the rapid development is too fast to catch up.'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m-----Applications of deep learning in stock market prediction: Recent progress  -----\u001b[0m\n",
      "\n",
      "\n",
      "Stock market prediction has been a classical yet challenging problem, with the attention from both economists and computer scientists. With the purpose of building an effective prediction model, both linear and machine learning tools have been explored for the past couple of decades. Lately, deep learning models have been introduced as new frontiers for this topic and the rapid development is too fast to catch up. Hence, our motivation for this survey is to give a latest review of recent works on deep learning models for stock market prediction. We not only category the different data sources, various neural network structures, and common used evaluation metrics, but also the implementation and reproducibility. Our goal is to help the interested researchers to synchronize with the latest progress and also help them to easily reproduce the previous studies as baselines. Based on the summary, we also highlight some future research directions in this topic.\n",
      "\n",
      "\n",
      "\u001b[1m-----Jointly modeling transfer learning of industrial chain information and deep learning for stock prediction  -----\u001b[0m\n",
      "\n",
      "\n",
      "The industrial chain information is introduced to improve the stock forecast results.DM test was carried out on the results, conclusion was statistically supported.An interpreter based on LIME algorithm is constructed to explain the results.The investment strategy is constructed, and the yield of maturity exceeds that of the buy-and-hold strategy.\n",
      "\n",
      "\n",
      "\u001b[1m-----Stock market prediction with deep learning: The case of China  -----\u001b[0m\n",
      "\n",
      "\n",
      "We consider stock price charts as images and use deep learning neural networks (DLNNs) for image modeling. DLNNs can imitate the work of a technical analyst to predict stock price movements in the short term with price charts and stock fundamentals (e.g., price-to-earnings ratio). We find that a deep learning model performs better than a single-layer model in the prediction of the Chinese stock market. DLNNs provide customizable statistical tools for analyzing price charts effectively. More importantly, price trends established by different periods of past daily closing prices dominate stock fundamentals in predicting future price movements.\n",
      "\n",
      "\n",
      "\u001b[1m-----Ensemble deep learning framework for stock market data prediction (EDLFDP)  -----\u001b[0m\n",
      "\n",
      "\n",
      "Stock market variation data is collected in one form of breaking news from various finance web sites. The free financial data about companies is available on Internet Portals .The stock market sentiment changes with at a fraction due to major financial reforms, weather, natural disasters, and news events. Online finance news generates large amount of data. The market reforms are predicted with various machine learning algorithms. The term frequency-inverse document frequency (TF-IDF) features extracted from online news data for various companies of Bombay Stock Exchange are used along with other stock market features for prediction. The next day's stock price is predicted using ensemble deep learning framework. The data set is optimized by various deep learning techniques to get more accurate results. The proposed model produces approximately 85 of accurate prediction with deep learning framework. The market trends in terms of high and low stock values are matching exactly. The results can be further improved with use of high frequency trading algorithms.\n",
      "\n",
      "\n",
      "\u001b[1m-----A hybrid model integrating deep learning with investor sentiment analysis for stock price prediction  -----\u001b[0m\n",
      "\n",
      "\n",
      "Whether stock prices are predictable has been the center of debate in academia. In this paper, we propose a hybrid model that combines a deep learning approach with a sentiment analysis model for stock price prediction. We employ a Convolutional Neural Network model for classifying the investors’ hidden sentiments, which are extracted from a major stock forum. We then propose a hybrid research model by applying the Long Short-Term Memory (LSTM) Neural Network approach for analyzing the technical indicators from the stock market and the sentiment analysis results from the first step. Furthermore, this work has conducted real-life experiments from six key industries of three time intervals on the Shanghai Stock Exchange (SSE) to validate the effectiveness and applicability of the proposed model. The experiment results indicate that the proposed model has achieved better performance in classifying investor sentiments than the baseline classifiers, and this hybrid approach performs better in predicting stock prices compared to the single model and the models without sentiment analysis.\n",
      "\n",
      "\n",
      "\u001b[1m-----LSTMbased Deep Learning Model for Stock Prediction and Predictive Optimization Model  -----\u001b[0m\n",
      "\n",
      "\n",
      "This paper proposes a novel method of regression for stock price prediction.The regression model has been implemented on LSTM deep neural network.The predictions once obtained are used to construct an investment portfolio using a new portfolio optimization model.Comparative analysis have been carried out with other models available in literature.It is observed that the proposed model can be effective in predicting time-series data such as stock returns as well as in constructing optimal portfolios.\n",
      "\n",
      "\n",
      "\u001b[1m-----Stock price prediction using deep learning and frequency decomposition  -----\u001b[0m\n",
      "\n",
      "\n",
      "Nonlinearity and high volatility of financial time series have made it difficult to predict stock price. However, thanks to recent developments in deep learning and methods such as long short-term memory (LSTM) and convolutional neural network (CNN) models, significant improvements have been obtained in the analysis of this type of data. Further, empirical mode decomposition (EMD) and complete ensemble empirical mode decomposition (CEEMD) algorithms decomposing time series to different frequency spectra are among the methods that could be effective in analyzing financial time series. Based on these theoretical frameworks, we propose novel hybrid algorithms, i.e., CEEMD-CNN-LSTM and EMD-CNN-LSTM, which could extract deep features and time sequences, which are finally applied to one-step-ahead prediction. The concept of the suggested algorithm is that when combining these models, some collaboration is established between them that could enhance the analytical power of the model. The practical findings confirm this claim and indicate that CNN alongside LSTM and CEEMD or EMD could enhance the prediction accuracy and outperform other counterparts. Further, the suggested algorithm with CEEMD provides better performance compared to EMD.\n",
      "\n",
      "\n",
      "\u001b[1m-----Liquidity prediction on Vietnamese stock market using deep learning  -----\u001b[0m\n",
      "\n",
      "\n",
      "Machine-learning methods have recently been successfully used in different areas, but there are also many fields where such studies have not been carried out. One of them is advanced issue regarding liquidity prediction and forecasting of financial time series. It is a very challenging task because this sphere is highly volatile and dynamic, especially if we consider emerging stock markets like the Vietnamese one. The authors proposed deep learning as the most modern technique to forecast the future directions of an emerging stock market and developed a predictive model to forecast liquidity for such a market. A fully-connected neural network based on Multilayer Perceptron (MLP), Mixed Deep Learning (MDL), and Linear Regression (LR) was tested. The following metrics were used: mean absolute error (MAE) and mean square error (MSE), and the best values of MSE in the MDL model were achieved. Based on the proposed model, which is the main contribution of the paper, better investment decisions can be achieved. The authors’ solution is dedicated to and empirically verified on the Vietnamese stock market, so future works should extend the model to other ones, emerging and developed alike.\n",
      "\n",
      "\n",
      "\u001b[1m-----The role of textextracted investor sentiment in Chinese stock price prediction with the enhancement of deep learning  -----\u001b[0m\n",
      "\n",
      "\n",
      "Whether investor sentiment affects stock prices is an issue of long-standing interest for economists. We conduct a comprehensive study of the predictability of investor sentiment, which is measured directly by extracting expectations from online user-generated content (UGC) on the stock message board of Eastmoney.com in the Chinese stock market. We consider the influential factors in prediction, including the selections of different text classification algorithms, price forecasting models, time horizons, and information update schemes. Using comparisons of the long short-term memory (LSTM) model, logistic regression, support vector machine, and Naïve Bayes model, the results show that daily investor sentiment contains predictive information only for open prices, while the hourly sentiment has two hours of leading predictability for closing prices. Investors do update their expectations during trading hours. Moreover, our results reveal that advanced models, such as LSTM, can provide more predictive power with investor sentiment only if the inputs of a model contain predictive information.\n",
      "\n",
      "\n",
      "\u001b[1m-----An integrated framework of deep learning and knowledge graph for prediction of stock price trend: An application in Chinese stock exchange market  -----\u001b[0m\n",
      "\n",
      "\n",
      "Many studies have been carried out on stock price trend prediction, but most of them focused on the public market data and did not utilize the trading behaviors owing to the unavailability of real transaction records data. In fact, trading behaviors can better reflect the market movements, and the fusion of trading information and market information can further improve the prediction accuracy. In this paper, we propose a deep neural network model using the desensitized transaction records and public market information to predict stock price trend. Considering the correlation between stocks, our method utilizes the knowledge graph and graph embeddings techniques to select the relevant stocks of the target for constructing the market and trading information. Given the considerable number of investors and the complexity of transaction records data, the investors are clustered to reduce the dimensions of the trading feature matrices, and then the matrices are fed into the convolutional neural network to unearth the investment patterns. Eventually, the attention-based bidirectional long short-term memory network can predict the stock price trends for financial decision support. The experiments on the price movement direction and trend prediction show that our method achieves the best performance in comparison with other prediction baselines.\n",
      "\n",
      "\n",
      "\u001b[1m-----An improved Stacking framework for stock index prediction by leveraging treebased ensemble models and deep learning algorithms  -----\u001b[0m\n",
      "\n",
      "\n",
      "Stock price index is an essential component of financial systems and indicates the economic performance in the national level. Even if a small improvement in its forecasting performance will be highly profitable and meaningful. This manuscript input technical features together with macroeconomic indicators into an improved Stacking framework for predicting the direction of the stock price index in respect of the price prevailing some time earlier, if necessary, a month. Random forest (RF), extremely randomized trees (ERT), extreme gradient boosting (XGBoost) and light gradient boosting machine (LightGBM), which pertain to the tree-based algorithms, and recurrent neural networks (RNN), bidirectional RNN, RNN with long short-term memory (LSTM) and gated recurrent unit (GRU) layer, which pertain to the deep learning algorithms, are stacked as base classifiers in the first layer. Cross-validation method is then implemented to iteratively generate the input for the second level classifier in order to prevent overfitting. In the second layer, logistic regression, as well as its regularized version, are employed as meta-classifiers to identify the unique learning pattern of the base classifiers. Empirical results over three major U.S. stock indices indicate that our improved Stacking method outperforms state-of-the-art ensemble learning algorithms and deep learning models, achieving a higher level of accuracy, F-score and AUC value. Besides, another contribution in our research paper is the design of a Lasso (least absolute shrinkage and selection operator) based meta-classifier that is capable of automatically weightingselecting the optimal base learners for the forecasting task. Our findings provide an integrated Stacking framework in the financial area.\n",
      "\n",
      "\n",
      "\u001b[1m-----Deep learningbased feature engineering for stock price movement prediction  -----\u001b[0m\n",
      "\n",
      "\n",
      "Stock price modeling and prediction have been challenging objectives for researchers and speculators because of noisy and non-stationary characteristics of samples. With the growth in deep learning, the task of feature learning can be performed more effectively by purposely designed network. In this paper, we propose a novel end-to-end model named multi-filters neural network (MFNN) specifically for feature extraction on financial time series samples and price movement prediction task. Both convolutional and recurrent neurons are integrated to build the multi-filters structure, so that the information from different feature spaces and market views can be obtained. We apply our MFNN for extreme market prediction and signal-based trading simulation tasks on Chinese stock market index CSI 300. Experimental results show that our network outperforms traditional machine learning models, statistical models, and single-structure(convolutional, recurrent, and LSTM) networks in terms of the accuracy, profitability, and stability.\n",
      "\n",
      "\n",
      "\u001b[1m-----Deep learning networks for stock market analysis and prediction: Methodology, data representations, and case studies  -----\u001b[0m\n",
      "\n",
      "\n",
      "We offer a systematic analysis of the use of deep learning networks for stock market analysis and prediction. Its ability to extract features from a large set of raw data without relying on prior knowledge of predictors makes deep learning potentially attractive for stock market prediction at high frequencies. Deep learning algorithms vary considerably in the choice of network structure, activation function, and other model parameters, and their performance is known to depend heavily on the method of data representation. Our study attempts to provides a comprehensive and objective assessment of both the advantages and drawbacks of deep learning algorithms for stock market analysis and prediction. Using high-frequency intraday stock returns as input data, we examine the effects of three unsupervised feature extraction methods—principal component analysis, autoencoder, and the restricted Boltzmann machine—on the network’s overall ability to predict future market behavior. Empirical results suggest that deep neural networks can extract additional information from the residuals of the autoregressive model and improve prediction performance; the same cannot be said when the autoregressive model is applied to the residuals of the network. Covariance estimation is also noticeably improved when the predictive network is applied to covariance-based market structure analysis. Our study offers practical insights and potentially useful directions for further investigation into how deep learning networks can be effectively used for stock market analysis and prediction.\n",
      "\n",
      "\n",
      "\u001b[1m-----NSE Stock Market Prediction Using DeepLearning Models  -----\u001b[0m\n",
      "\n",
      "\n",
      "The neural network, one of the intelligent data mining technique that has been used by researchers in various areas for the past 10 years. Prediction and analysis of stock market data have got an important role in today’s economy. The various algorithms used for forecasting can be categorized into linear (AR, MA, ARIMA, ARMA) and non-linear models (ARCH, GARCH, Neural Network). In this paper, we are using four types of deep learning architectures i.e Multilayer Perceptron (MLP), Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM) and Convolutional Neural Network (CNN) for predicting the stock price of a company based on the historical prices available. Here we are using day-wise closing price of two different stock markets, National Stock Exchange (NSE) of India and New York Stock Exchange (NYSE). The network was trained with the stock price of a single company from NSE and predicted for five different companies from both NSE and NYSE. It has been observed that CNN is outperforming the other models. The network was able to predict for NYSE even though it was trained with NSE data. This was possible because both the stock markets share some common inner dynamics. The results obtained were com- pared with ARIMA model and it has been observed that the neural networks are outperforming the existing linear model (ARIMA).\n",
      "\n",
      "\n",
      "\u001b[1m-----Stock index prediction and uncertainty analysis using multiscale nonlinear ensemble paradigm of optimal feature extraction, twostage deep learning and Gaussian process regression  -----\u001b[0m\n",
      "\n",
      "\n",
      "Reliable prediction of stock indexes can be highly valuable for financial decision-making and risk management. The stock market is a highly complicated nonlinear system which makes it difficult to present accurate predictors. In this paper, an innovative multi-scale nonlinear ensemble paradigm is proposed for stock index prediction and uncertainty analysis, which consists of an optimal feature extraction including variational mode decomposition and auto-encoder, a two-stage deep learning based on recurrent neural network and long short-term memory, and Gaussian process regression. The optimal feature extraction is proposed to extract the optimal features of stock index fluctuations and eliminate the disturbance of illusive components. The two-stage deep learning is developed to conduct the prediction of each feature sub-signal and implement its nonlinear integration. The Gaussian process regression is utilized to construct the interval prediction of the original stock signal and analyze the uncertainties of stock market. The validity of the developed model is verified by the data from SP 500, Dow Jones index and NASDAQ. After a series of comparisons, the mean absolute percentage errors of the proposed model in SP 500, Dow Jones index and NASDAQ are 0.55, 0.65 and 1.11, respectively. These results fully verify the effectiveness of proposed model.\n",
      "\n",
      "\n",
      "\u001b[1m-----COVID19HPSMP: COVID19 adopted Hybrid and Parallel deep information fusion framework for stock price movement prediction  -----\u001b[0m\n",
      "\n",
      "\n",
      "Introduction of COVID-19 related PRIce MOvement prediction (COVID19 PRIMO) dataset.Proposing COVID-19 adopted hybrid deep fusion framework for stock price prediction.Integration of COVID-19 related Twitter data with extended horizon market data.Generalization performance of price movement prediction across various scenarios.Outperforming stand-alone (non-hybrid) deep learning-based price prediction models.\n",
      "\n",
      "\n",
      "\u001b[1m-----Forecasting the overnight return direction of stock market index combining global market indices: A multiplebranch deep learning approach  -----\u001b[0m\n",
      "\n",
      "\n",
      "We focus on the daily close-to-open return (RC−O) of stock market index (SMI).We propose a novel MBCNN to forecast the direction of daily RC−O.Multiple convolutional units are used to extract features from intraregional SMIs.GA is used to determine the optimal structure and hyper-parameters of MBCNN.Performance of the proposed MBCNN is better than other competing models.\n",
      "\n",
      "\n",
      "\u001b[1m-----Stock movement prediction via gated recurrent unit network based on reinforcement learning with incorporated attention mechanisms  -----\u001b[0m\n",
      "\n",
      "\n",
      "The recent advances usually mine market information from the chaotic data to conduct a stock movement prediction task. However, the current stock price movement prediction approaches mainly compute attention weighted sum of the global contextual semantic embeddings, which fails to combine local word-level or char-level ones to jointly learn news-level representation. Moreover, for Chinese stock price movement prediction task, some collected news texts are chaotic even irrelevant to the target stock. It suggests that the models need filter some news-level representations (viewed as noises) to enhance the performance. To that aim, we develop a novel stock price movement prediction network via bidirectional gated recurrent unit (GRU) network based on reinforcement learning (RL) with incorporated attention mechanism. In specific, to reduce the noise of news texts and learn news-level representation with more abundant semantics, two novel attention mechanisms respectively based on add and dot operation were first proposed in this work. We then design a novel GRU structure based on RL to filter some irrelated news-level representations (i.e., news-level noises) and capture abundant long-term dependencies. Finally, the experimental results show that the proposed model far outperforms the recent advances and achieves state-of-the-art performances.\n",
      "\n",
      "\n",
      "\u001b[1m-----Deep learning with multiple scale attention and direction regularization for asset price prediction  -----\u001b[0m\n",
      "\n",
      "\n",
      "Forecasting the stock price is a challenging task due to its complex dynamic behaviors, affected by long-term trends, seasonal changes, cyclical changes, and irregular changes. Although many deep learning techniques have been applied to stock price forecasting, few of them have a deep insight into these complex behaviors. In this work, we propose a four-step hybrid model, named ESTA-Net, to adaptively extract these behavior patterns for stock price forecasting. Firstly, the empirical mode decomposition is applied to decompose a closing price sequence into intrinsic mode functions (IMFs). The goal of this step is to extract multiple quasi-stationary features of different time scales from the historical closing price sequence. Secondly, each IMF is modeled and forecasted by a temporal attention long short term memory (TALSTM) network. The TALSTM network is designed to capture the long term dependency of each IMF. Thirdly, the learned deep representations of IMFs are fed into a scale attention network (SANet), which adaptively selects relevant deep representations of multiple time scale features extracted from the historical price sequence. Finally, these learned deep features are fed into a fully connected layer to predict the future closing price. In addition, to make the proposed model learn the movement direction of the closing price, we propose a novel regularization term, i.e. the direction regularization term, to train the proposed model. This regularization term measures the inconsistency between the predicted movement direction and the actual movement direction of the closing price. Experiments show that the proposed model significantly outperforms benchmark models. Particularly, on seven financial market indices, the proposed model with the direction regularization term achieves the highest POCID (32.04 higher than that of CNN) and the lowest MAPE (37.36 lower than that of DA-RNN).\n",
      "\n",
      "\n",
      "\u001b[1m-----Portfolio optimization with return prediction using deep learning and machine learning  -----\u001b[0m\n",
      "\n",
      "\n",
      "Integrating return prediction of traditional time series models in portfolio formation can improve the performance of original portfolio optimization model. Since machine learning and deep learning models have shown overwhelming superiority than time series models, this paper combines return prediction in portfolio formation with two machine learning models, i.e., random forest (RF) and support vector regression (SVR), and three deep learning models, i.e., LSTM neural network, deep multilayer perceptron (DMLP) and convolutional neural network. To be specific, this paper first applies these prediction models for stock preselection before portfolio formation. Then, this paper incorporates their predictive results in advancing mean–variance (MV) and omega portfolio optimization models. In order to present the superiority of these models, portfolio models with autoregressive integrated moving average’s return prediction are used as benchmarks. Evaluation is based on historical data of 9 years from 2007 to 2015 of component stocks of China securities 100 index. Experimental results show that MV and omega models with RF return prediction, i.e., RF+MVF and RF+OF, outperform the other models. Further, RF+MVF is superior to RF+OF. Due to the high turnover of these two models, this paper discusses their performance after deducting the transaction fee cased by turnover. Experiments present that RF+MVF still performs the best among MVF models and omega model with SVR prediction (SVR+OF) performs the best among OF models. Moreover, RF+MVF performs better than SVR+OF and high turnover erodes nearly half of their total returns especially for RF+OF and RF+MVF. Therefore, this paper recommends investors to build MVF with RF return prediction for daily trading investment.\n",
      "\n",
      "\n",
      "\u001b[1m-----A systematic review of stock market prediction using machine learning and statistical techniques  -----\u001b[0m\n",
      "\n",
      "\n",
      "The stock market prediction patterns are seen as an important activity and it is more effective. Hence, stock prices will lead to lucrative profits from sound taking decisions. Because of the stagnant and noisy data, stock market-related forecasts are a major challenge for investors. Therefore, forecasting the stock market is a major challenge for investors to use their money to make more profit. Stock market predictions use mathematical strategies and learning tools. This paper provides a complete overview of 30 research papers recommending methods that include calculation methods, ML algorithms, performance parameters, and outstanding journals. The studies are selected based on research questions. Hence, these selected studies are helping to find the ML techniques along with their dataset for stock market prediction. Most widely ANN and NN techniques are used to achieve precise predictions of the stock market. While much amount of work is done, the latest stock market-related prediction methodology has many limitations. It can be assumed in this study that stock market forecasting is an integrated process and distinctive parameters for forecast the stock market should be considered more accurate.\n",
      "\n",
      "\n",
      "\u001b[1m-----Credit default prediction from usergenerated text in peertopeer lending using deep learning  -----\u001b[0m\n",
      "\n",
      "\n",
      "Digital technologies produce vast amounts of unstructured data that can be stored and accessed by traditional banks and fintech companies. We employ deep learning and several other techniques to extract credit-relevant information from user-generated text on Lending Club. Our results show that even short pieces of user-generated text can improve credit default predictions significantly. The importance of text is further supported by an information fusion analysis. Compared with other approaches that use text, deep learning outperforms them in almost all cases. However, machine learning models combined with word frequencies or topic models also extract substantial credit-relevant information. A comparison of six deep neural network architectures, including state-of-the-art transformer models, finds that the architectures mostly provide similar performance. This means that simpler methods (such as average embedding neural networks) offer performance comparable to more complex methods (such as the transformer networks BERT and RoBERTa) in this credit scoring setting.\n",
      "\n",
      "\n",
      "\u001b[1m-----An improved deep learning model for predicting stock market price time series  -----\u001b[0m\n",
      "\n",
      "\n",
      "As an important component of the economic market, the stock market has been concerned by many researchers. How to get the trend of the stock market and predict the stock price is a problem that many researchers are studying. In previous works, the prediction methods are mainly focused on statistical models and traditional neural network models which are relatively popular in recent years. Deep learning is not often used in the field of financial time series, but it has a strong learning ability and is suitable for complex time series such as financial time series. In particular, the LSTM network has the function of long-term memory because of its cyclic structure, so it is very suitable for financial time series prediction in theory. In the study, a novel stock closing price forecasting framework is proposed, which has a higher prediction than traditional models. The data processing part, the deep learning predictor part, and the predictor optimization method are the components of this deep hybrid framework. Data processing includes empirical wavelet transform (EWT) based preprocessing and outlier robust extreme learning machine (ORELM) model based post-processing. Long short-term memory (LSTM) network based deep learning network predictor, as the main part of the mixed frame, is jointly optimized by dropout strategy and particle swarm optimization (PSO) algorithm. Each algorithm in the hybrid framework can give full play to its own functions to achieve better prediction accuracy. In order to verify the performance of the model, three challenging datasets are selected for forecasting experiments. Some comparative models are also selected to prove the effectiveness of the proposed framework. Experimental results show that the hybrid framework proposed in the study has the best prediction accuracy and can be applied to stock market monitoring or financial data analysis and research.\n",
      "\n",
      "\n",
      "\u001b[1m-----Machine learning for liquidity prediction on Vietnamese stock market  -----\u001b[0m\n",
      "\n",
      "\n",
      "As a critical consideration in investment decisions, stock liquidity has significance for all stakeholders in the market. It also has implications for the stock market’s growth. Liquidity enables investors and issuers to meet their requirements regarding investment, financing or hedging, reducing investment costs and the cost of capital. The aim of this paper is to develop the machine learning models for liquidity prediction. The subject of research is the Vietnamese stock market, focusing on the recent years - from 2011 to 2019. Vietnamese stock market differs from developed markets and emerging markets. It is characterized by a limited number of transactions, which are also relatively small. The Multilayer Perceptron, Long-Short Term Memory and Linear Regression models have been developed. On the basis of the experimental results, it can be concluded that the LSTM model allows for prediction characterized by lowest value of MSE. The results of research can be used for developing the methods for decision support on stock markets.\n",
      "\n",
      "\n",
      "\u001b[1m-----Market sentimentaware deep reinforcement learning approach for stock portfolio allocation  -----\u001b[0m\n",
      "\n",
      "\n",
      "The stock market currently remains one of the most difficult systems to model in finance. Hence, it is a challenge to solve stock portfolio allocation wherein an optimal investment strategy must be found for a curated collection of stocks that effectively maximizes return while minimizing the risk involved. Deep reinforcement learning approaches have shown promising results when used to automate portfolio allocation, by training an intelligent agent on historical stock prices. However, modern investors are actively engaging with digital platforms such as social media and online news websites to understand and better analyze portfolios. The overall attitude thus formed by investors toward a particular stock or financial market is known as market sentiment. Existing approaches do not incorporate market sentiment which has been empirically shown to influence investor decisions. In our paper, we propose a novel deep reinforcement learning approach to effectively train an intelligent automated trader, that not only uses the historical stock price data but also perceives market sentiment for a stock portfolio consisting of the Dow Jones companies. We demonstrate that our approach is more robust in comparison to existing baselines across standardized metrics such as the Sharpe ratio and annualized investment return.\n"
     ]
    }
   ],
   "source": [
    "titles = list(Summarize.text_dict.keys())\n",
    "for title in titles:\n",
    "    print(\"\\n\")\n",
    "    print(\"\\033[1m\" + f\"-----{title}-----\" + \"\\033[0m\")\n",
    "    print(\"\\n\")\n",
    "    print(Summarize.text_dict[title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.sciencedirect.com/science/article/pii/S0957417421009441',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0957417421015669',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S1544612321002762',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S2666285X2100008X',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0957417421004607',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S2193943821001175',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0957417420310228',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S187705092032144X',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0169207020300625',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S1568494620301459',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0378437119313093',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0950705118305264',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0957417417302750',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S1877050918307828',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S1568494621008206',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0957417421012380',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0957417422000082',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0925231221014508',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0957417421011647',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0957417420307521',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S2214785320390337',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S037722172101078X',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S1051200420300865',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S1877050921018718',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S2215098621000070']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Summarize.urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary2 = Summarize.get_summary(\"E-government\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'While much has changed regarding e-government adoption and use by cities and their residents, it remains difficult to contextualize these changes and what they might mean for the development of e-government overall. Adopting e-government services is an innovative practice and there are a number of reasons why local governments might be expected to be particularly slow when it comes to innovation. Most cities have limited communications budgets and are severely restricted as to the amount of resources that could be utilized for potential upgrades.'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m-----Two decades of egovernment diffusion among local governments in the United States  -----\u001b[0m\n",
      "\n",
      "\n",
      "While much has changed regarding e-government adoption and use by cities and their residents, it remains difficult to contextualize these changes and what they might mean for the development of e-government overall. Adopting e-government services is an innovative practice and there are a number of reasons why local governments might be expected to be particularly slow when it comes to innovation. Most cities have limited communications budgets and are severely restricted as to the amount of resources that could be utilized for potential upgrades. At the same time, the incentive for local governments to innovate is less than many other organizations because cities and towns across the nation have small, targeted audiences, namely the residents that use their services. Local governments also lack competition that exists for most other political organizations in America. All of these characteristics add up to extremely low expected level of innovation, or innovativeness for local governments around the nation (Epstein, 2018; Rogers, 2003).\n",
      "\n",
      "\n",
      "\u001b[1m-----Conceptualizing citizentocitizen (C2C) interactions within the Egovernment domain  -----\u001b[0m\n",
      "\n",
      "\n",
      "Advances in technology increasingly empowered citizens to become active seekers and even co-producers of e-government information and services rather than being only passive recipients. Citizens' interactions with each other reached such a point that they could contribute to the quality and quantity of e-government services. Examples of this citizen-to-citizen (C2C) interactions adding value to current e-government services or triggering new and innovative ones are increasingly observed worldwide. Although C2C interactions is not a new phenomenon, it is a relatively overlooked topic in e-government studies. Current e-government literature is insufficient in exploring and explaining the evolving nature, increasing occurrence, and various outcomes of these interactions. This article aims to fill the gap in the e-government literature by analyzing C2C interactions in detail and discusses how to regulate the C2C interaction processes and their useful and harmful outcomes.\n",
      "\n",
      "\n",
      "\u001b[1m-----Why farmers perceive the use of egovernment services as an administrative burden: A conceptual framework on influencing factors  -----\u001b[0m\n",
      "\n",
      "\n",
      "In many countries around the world, family farms are expected to use e-government services to handle data exchange electronically via the internet with the government to fulfill their information obligations. This paper aims to explore the factors influencing the extent to which farmers perceive the use of such services as burdensome, and to develop a framework to categorize these factors for the farming sector. To do this, we extracted a conceptual framework designed for commercial businesses and adapted it to the farming sector. We employed a qualitative case study in Switzerland and conducted face-to-face interviews with six farmers using contrast sampling. The interviews were examined by applying thematic analysis. We found influencing factors from four different fields: (1) farm and farmer characteristics (e.g., farm structure, farmer's attitude toward ICT, farmer's ICT competence, use of external support, work organization, and infrastructure), (2) usage characteristics of e-government services (e.g. quantity and frequency of data entry, and period in use), (3) perceived characteristics of e-government (e.g., network, documentation, software design, complexity, farm compatibility, and duplication), and (4) perceived farm impact (data-security). We further found that the use of e-government services has no organizational benefits for family farms. Our findings provide a conceptual framework for understanding why e-government services for farmers might contribute to either a decrease or increase in their perceived administrative burden. It further provides policy-relevant information about the factors that play a role in digital direct payment administration to reduce farmers' administrative burdens.\n",
      "\n",
      "\n",
      "\u001b[1m-----Analyzing egovernment design science artifacts: A systematic literature review  -----\u001b[0m\n",
      "\n",
      "\n",
      "Design science as a research paradigm is gaining popularity in the information systems (IS) discipline. E-government research explores IS artifacts designed to improve the quality and efficiency of public administration and service. This paper utilizes the E-government Design Research Model (EgovDR Model) to review e-government designs. Through a comprehensive literature review, this paper identifies prototypical e-government tasks for design science implementation and the corresponding solutions. We demonstrate whether and how the development and evolution of e-government designs continue to gain relevance in design science research. Additionally, this paper identifies and analyzes the theories employed in the literature to illustrate how the EgovDR Model has facilitated e-government designs in increasing rigor over time. Our findings indicate the majority of the workpractice tasks in existing e-government designs are decision-support tasks.\n",
      "\n",
      "\n",
      "\u001b[1m-----Future of eGovernment: An integrated conceptual framework  -----\u001b[0m\n",
      "\n",
      "\n",
      "The information and hyper-connectivity revolutions have caused significant disruptions in citizens’ interactions with governments all over the world. Failures in implementing e-government interventions suggest the lack of an integrated approach in understanding e-government as a discipline. In this study, we present an overarching and integrated conceptual framework of e-government grounded in robust qualitative research to describe the factors that must be integrated to implement e-government successfully. Drawing insights from 168 in-depth interviews conducted with multiple stakeholders in India, this study defines e-government as a multidimensional construct with customer orientation, channel orientation and technology orientation as its antecedents. Building on customer orientation and relationship marketing theories, this study proposes that the most significant factor impacting success in implementing e-government projects is citizen orientation, followed by channel orientation and technology orientation. The study also identifies the digital divide, economic growth and political stability as moderators of e-government. Furthermore, the study proposes the tangible and intangible outcomes of e-government with perceived privacy and shared understanding as moderating conditions. Finally, the study presents relevant theoretical and practical implications with future research directions.\n",
      "\n",
      "\n",
      "\u001b[1m-----A critical appraisal of the Western Australian local government review panel’s recommendations  -----\u001b[0m\n",
      "\n",
      "\n",
      "Compared with most other developed nations, Australian local government policymakers have traditionally relied heavily on structural reform based on compulsory council consolidation as their chief instrument of municipal reform. Western Australia (WA) launched its most recent attempt at local government reform in November 2017 with the appointment of a Local Government Review Panel to make recommendations on improving its Local Government Act 1995. The WA Government released the Final Report: Recommendations for a New Local Government Act for Western Australia prepared by the Panel in August 2020. The Final Report offers a host of recommendations for improving the Local Government Act 1995, the great majority of which represent uncontroversial improvements to the Act. However, Recommendation 8 calls for the establishment of a Local Government Commission empowered to make recommendations on municipal mergers and Recommendation 10 proposes the formation of community boards to facilitate municipal representation in large councils. This practice insight paper critically examines these two contentious recommendations in the light of extant empirical evidence. This serves to highlight the contrast between the weight of empirical evidence in the literature with the ‘evidence-free’ nature of Recommendations 8 and 10.\n",
      "\n",
      "\n",
      "\u001b[1m-----Determinants of satisfaction among social entrepreneurs in eGovernment services  -----\u001b[0m\n",
      "\n",
      "\n",
      "Information Technology–enabled e-Governance outlets are being increasingly used in developing economies to facilitate the delivery of e-Government services. These outlets are managed by social entrepreneurs who serve as an intermediary between the citizen and the government. With social entrepreneurship and stakeholder theories as underpinnings and model validation with data from 232 respondents, the current work suggests that social entrepreneurs' satisfaction is derived from a positive public image and satisfaction with stakeholders. The two factors fulfill the entrepreneur’s communion motives and are derived from their economic well-being, an agency motive, which itself is an outcome of the e-Government website service quality. This study also establishes the intervening role of process and the government support for enhancing the social entrepreneur’s economic wellbeing. The study brings the unique perspectives of social entrepreneurship to e-Government service delivery and provides recommendations for policymakers to focus on the satisfaction of such intermediaries for sustainable inclusion into the digital mainstream.\n",
      "\n",
      "\n",
      "\u001b[1m-----Blockchain and egovernment innovation: Automation of public information processes  -----\u001b[0m\n",
      "\n",
      "\n",
      "The emergence of the blockchain phenomenon affects various aspects of human life. Public sector reforms are also influenced by this trend. E-government leaders around the world are tentatively beginning to grasp the potential of blockchain and other distributed ledger technologies, especially with regard to their promise to provide more decentralized information management solutions in government and make public digital platforms more transparent and efficient. Software developers around the world have come up with a range of digital solutions to accelerate these reforms. Given the multidimensional nature of e-government, it is interesting to understand in which areas blockchain has the potential to promote innovation, what processes and procedures can be automated using blockchain technology, and what illustrative examples of government efficiency can be observed in this area.\n",
      "\n",
      "\n",
      "\u001b[1m-----Improving the assessment of digital services in government websites: Evidence from the Mexican State government portals ranking  -----\u001b[0m\n",
      "\n",
      "\n",
      "We explore the empirical consistency of conceptual categories used to measure government portals functionality.We use data from a Mexican ranking of government portals.We found 22 factors in 5 main categories: Information, Interaction, Transaction, Integration and Participation.We found internal inconsistencies among concepts and categories that may be useful to improve the ranking.This method can be used to other popular digital government rankings.\n",
      "\n",
      "\n",
      "\u001b[1m-----Discerning the effect of privacy information transparency on privacy fatigue in egovernment  -----\u001b[0m\n",
      "\n",
      "\n",
      "Developments in information technology (IT) have exposed the challenges, needs, and workings of the society around us. Despite this fact, they have also aligned these facets into streamlined, coherent human convenient processes (Mutimukwe, Kolkowska,  Grönlund, 2019). This has benefited all sundry, particularly, organizations, and governments (Sharma, Metri, Dwivedi,  Rana, 2021). For instance, ITs have facilitated the search for information to improve decision making or facilitate services to consumers (Sabani, 2020). Despite these benefits, there is also evidence of their dissuasion to users' decisions due to the lack or inadequacy of information (Eijk, Asghari, Winter,  Narayanan, 2019). For example, information provided on some service platforms is either inadequate or difficult to understand in order to satisfy information needs of users (Tejedo-Romero  Araujo, 2020). This challenge of insufficient information needs of users often leads to the issue of limited information transparency (Abu-Shanab, 2013).\n",
      "\n",
      "\n",
      "\u001b[1m-----Exploring the optimal reverse supply chain for ewaste treatment under Chinese government subsidy  -----\u001b[0m\n",
      "\n",
      "\n",
      "This study aims to analyze the influence of Chinese government subsidy on e-waste treatment formal and informal reverse supply chains (RSC) and to explore the optimal formal channel structure. Under the formal recycler-Stackelberg game, we establish three game theory models respectively under the conditions of price insensitive and price sensitive overall collection quantity. In each model, a dual-channel RSC, the green technology investment decision of formal recycler and a subsidy for formal recycler are modelled. Besides, the three models are different in collectors and collection effort implementers of the formal channel. Through mathematical modelling and comparison analysis, the study concludes that the best choice for the formal recycling enterprises is to establish its own collection channel or centralize other independent collection channels. Under the condition of price insensitive overall collection quantity, the suboptimal choice is to implement collection effort positively. Under the condition of price sensitive overall collection quantity, the suboptimal choice is to outsource the collection effort when formal recycling enterprises benefit more from the collection effort. And the phenomenon is more outstanding when the overall collection quantity can be greatly improved by the collection price. For governments, they are recommended to prudently implement the subsidy and determine the amount of subsidy because the subsidy may benefit informal channels and the effectiveness of the subsidy varies along with formal channel structures. This study is beneficial for the promotion of formal RSC by providing the optimal channel structure for formal recycling enterprises and indicating the optimal subsidy for governments.\n",
      "\n",
      "\n",
      "\u001b[1m-----Effects of Predictors of Citizens' Attitudes and Intention to Use Open Government Data and Government 2.0  -----\u001b[0m\n",
      "\n",
      "\n",
      "Therefore, academic and professional scenarios have faced new research questions and new challenges due to the combination of e-government with the continuous advance of technology (Wirtz  Daiser, 2018). Similarly, the emergence of further information and communication technologies has led to innovations in the democratic process based on the transparency of government actions, citizens' political participation, and collaboration between governments and citizens (Wirtz, Weyerer and Rösch, 2017a, Wirtz, Weyerer and Rösch, 2017b). These three aspects constitute the principles of open government (Chun, Shulman, Sandoval,  Hovy, 2010; Lee  Kwak, 2012), gaining attention from the public and the scientific community (Wirtz, Weyerer and Rösch, 2017a, Wirtz, Weyerer and Rösch, 2017b) and popularity in the political landscape (Meijer, Curtin,  Hillebrandt, 2012).\n",
      "\n",
      "\n",
      "\u001b[1m-----Can egovernment limit the scope of the informal economy?  -----\u001b[0m\n",
      "\n",
      "\n",
      "The study explores the potential association between e-government and the informal economy. We find that e-government is a powerful instrument to lessen informal economic activities, which is robust to different estimation techniques, subsamples of developing countries, and a wide array of controls and alternative measures. The long-run effect of e-government on lessening informal production is substantially higher than the short-run effect. The strength of e-government appears to be in its entirety, although we find evidence of more influence driven by the development of telecommunications infrastructure. Interaction models show that e-government reinforces the effect of various factors on informal economy reduction. Panel Granger causality tests indicate that causality between e-government and shadow economy is bidirectional.\n",
      "\n",
      "\n",
      "\u001b[1m-----On the adoption of static analysis for software security assessment–A case study of an opensource egovernment project  -----\u001b[0m\n",
      "\n",
      "\n",
      "Static Application Security Testing (SAST) is a popular quality assurance technique in software engineering. However, integrating SAST tools into industry-level product development for security assessment poses various technical and managerial challenges. In this work, we reported results from a case study of adopting SAST as a part of a human-driven security assessment process in an open-source e-government project. We described how SASTs are selected, evaluated, and combined into a novel approach and adopted by security experts for software security assessment. The approach was preliminarily evaluated using semi-structured interviews. Our results show that while some SAST tools out-perform others, it is possible to achieve better performance by combining more than one SAST tools. The combined approach has the potential to aid the security assessment process for open-source software.\n",
      "\n",
      "\n",
      "\u001b[1m-----Can egovernment initiatives alleviate tax evasion? The moderation effect of ICT  -----\u001b[0m\n",
      "\n",
      "\n",
      "Drawing on modernization and institutional theories, this study tests the association between the digitalization of government services and tax evasion via the moderation effect of information and communication technologies (ICTs). The study's sample covers the years between 2006 and 2017 and contains 1677 country-year observations. The results of fixed effect analysis indicate that the six proxies for governments’ long-term vision and the digitalization of government services all play a significant role in alleviating tax evasion. Moreover, ICT adoption by society and citizens positively moderates the association between the digitalization of government services and tax evasion; that is, the digitalization of government services has a stronger effect on mitigating tax evasion in countries where ICT adoption is higher. The study suggests several implications for leveraging ICT in public service delivery, which may help countries reduce tax evasion and increase tax revenue. Specifically, public authorities should improve e-government structures and e-filing systems to facilitate taxpayers’ income tax declarations and payments.\n",
      "\n",
      "\n",
      "\u001b[1m-----Digital transformation toward AIaugmented public administration: The perception of government employees and the willingness to use AI in government  -----\u001b[0m\n",
      "\n",
      "\n",
      "The rapid advancement of AI technologies has dramatically expanded the technological possibilities of the government and the application of AI technologies in government has been accelerating into more substantial areas of government functions. Often coined as the Fourth Industrial Revolution, AI technologies are thought to transform the government and vastly improve its administrative capabilities adequate to meet the complex challenges of 21st-century society. In fact, with more sophisticated algorithms and greater availability of data (United States Government Accountability Office, 2018), AI has become an increasingly salient tool for public service and administrative decision-making. The U.S. federal government has used artificial intelligence to enhance capabilities such as fraud detection, regulatory decision-making, and civic engagement (Engstrom, Ho, Sharkey,  Cuéllar, 2020) and such trend seem to be accelerating with the application of AI technologies expanding its functional territories into more substantial areas of the government such as defense (autonomous weapons), regulation (“Regu-tech”), predictive analytics, cybersecurity, fraud detection and civic engagement (Ahn  Chen, 2020; Chenok  Yusti, 2018; Engstrom et al., 2020; Wirtz, Weyerer,  Geyer, 2019).\n",
      "\n",
      "\n",
      "\u001b[1m-----From Ebudgeting to smart budgeting: Exploring the potential of artificial intelligence in government decisionmaking for resource allocation  -----\u001b[0m\n",
      "\n",
      "\n",
      "Traditionally, the role of fiscal policy has been summarized in three interrelated functions: resource allocation, income distribution, and stabilization of the economy (Adler, 2021). The expenditure distribution in the budget should be dynamic because economic events are dynamic. The economic crises, pandemics, inflation, exchange rates, and other factors require fiscal policy in order to achieve economic growth and well-being. In this regard, one of the main problems in public budgeting is to reach the right spending distribution to meet the population's needs. Therefore, it is important to better understand which categories of public spending are or should be priorities for the benefit of society.\n",
      "\n",
      "\n",
      "\u001b[1m-----Uninsured idiosyncratic risk and the government asset Laffer curve  -----\u001b[0m\n",
      "\n",
      "\n",
      "We examine the long-run government asset Laffer curve, which shows the relationship between government asset income and government assets in the long run, under zero taxes.1 Our analysis is based on an Aiyagari (1994)-type model with heterogeneous households and incomplete asset markets. Households face uninsured idiosyncratic earnings risk and an exogenous borrowing limit. We also include endogenous labor supply, following previous works on fiscal policy using this framework.2 Firms produce output by renting capital and labor from households, whereas the government uses government asset income for government consumption and lump-sum transfers to households.\n",
      "\n",
      "\n",
      "\u001b[1m-----Challenges common service centers (CSCs) face in delivering egovernment services in rural India  -----\u001b[0m\n",
      "\n",
      "\n",
      "Advances in information and communication technologies (ICTs) over the last two decades have resulted in the more transparent working of public sector organisations and more effective service delivery (Dwivedi, Weerakkody,  Janssen, 2012; Sharma  Mishra, 2017). These technologies have enabled government services to go online, making them more accessible to citizens, leading to a phenomenon now popularly known as e-government (Dwivedi et al., 2017; Rana, Dwivedi,  Williams, 2013; Venkatesh, Thong, Chan,  Hu, 2016).\n",
      "\n",
      "\n",
      "\u001b[1m-----Creating Open Government Data ecosystems: Network relations among governments, user communities, NGOs and the media  -----\u001b[0m\n",
      "\n",
      "\n",
      "The introduction of Open Government Data (OGD) policies in many countries has been accompanied by high expectations in terms of better government transparency and accountability, public participation, innovation, and economic development (Janssen, Charalabidis,  Zuiderwijk, 2012; Ruijer, Grimmelikhuijsen,  Meijer, 2017; Zuiderwijk, Janssen,  Davis, 2014). However, a long list of disappointments has followed acknowledgment of several “myths” regarding the power of OGD to automatically create these benefits (Janssen et al., 2012). Scholars now tend to associate the actual fulfilment of these ambitious promises with the development of healthy open data ecosystems of both public and private actors that enable meaningful use of the information released via governmental portals (Dawes, Vidiasova,  Parkhimovich, 2016; Gupta, Panagiotopoulos,  Bowen, 2020; Oliveira, Barros Lima,  Farias Lóscio, 2019). In particular, OGD policies with the specific purpose to foster transparency, accountability and public participation need not only proactively reach out to potential users, but they must also create the conditions for effective data use in order to have an impact on both social capital and democratic decision-making (Fung, Russon Gilman,  Shkabatur, 2013; Ruijer et al., 2017).\n",
      "\n",
      "\n",
      "\u001b[1m-----Citizen engagement on local government Facebook pages: Experience from Aotearoa New Zealand  -----\u001b[0m\n",
      "\n",
      "\n",
      "This paper explores the role of local government Facebook pages in citizen engagement by focusing on two councils in Aotearoa New Zealand, the Dunedin City Council (DCC) and the Otago Regional Council (ORC). We investigate how these councils use their Facebook pages to communicate government matters with citizens, and how citizens engage with the councils using the pages. Examination of Facebook posts by the two councils from January to December 2019 reveals that citizens were ‘informed’ of various council-identified issues through the use of ‘passive’ posts. There were relatively scant ‘active’ posts, which hold greater potential for meaningful engagement. It is apparent that both councils are more managerial and less consultative and participatory in their approach to social media use for citizen engagement. We recommend that local governments can enhance the level of engagement by exploring ways to increase their page followers, using a combination of both active and passive posts frequently, increasing and experimenting with types of active posts, and adopting te reo Māori and minority languages to ensure an inclusive virtual environment. This study offers new insights for both local governments and social media researchers to rethink how to best utilise Facebook pages for effective e-participation.\n",
      "\n",
      "\n",
      "\u001b[1m-----How to deal with corruption? Examining the roles of egovernment maturity, government administrative effectiveness, and virtual social networks diffusion  -----\u001b[0m\n",
      "\n",
      "\n",
      "The role of e-government in combating corruption is an active area of research in Information Systems (IS). Drawing on the value framework for assessing e-government impact, and grounding our discussion on three theoretical perspectives, namely, (1) technological determinism theory, (2) general deterrence theory, and (3) Habermas’ public sphere perspective, we seek to explore how the diffusion of virtual social networks (VSNs) influences the relationships among e-government maturity, government administrative effectiveness, and corruption in a country. Our analyses based on publicly available archival data substantiate the (1) indirect relationships between e-government maturity in a country and corruption in three branches of its government (i.e., legislature, executive, and judiciary) through government administrative effectiveness, (2) interaction effect of VSN diffusion on the relationship between e-government maturity in a country and its government administrative effectiveness, and (3) interaction effects of VSN diffusion on the relationships between government administrative effectiveness in a country and its corruption dimensions. The key contributions of this research include the establishment of the (1) role of e-government in combating corruption in three branches of the government, and (2) idea of the public sphere in the context of VSN diffusion, and the subsequent exploration of its effects on e-government outcomes of a country.\n",
      "\n",
      "\n",
      "\u001b[1m-----Technological transformation of United States government documents librarianship  -----\u001b[0m\n",
      "\n",
      "\n",
      "The United States Federal Depository Library Program (FDLP) is a government mandated program that distributes government information to the populace through designated “depository” libraries. From the 1970s until today, due to advancing technology, government documents librarianship has undergone several transformative changes. Beginning with distribution of government information on microfilm through the appearance of electronic information in the 1980s exponentially increased the amount of information available to users, information that often came with a large learning curve to use. The proliferation of government information transformed government documents librarianship from a self-contained, stand-alone, bibliographically focused entity to a more forward-facing, user-centric focus.\n",
      "\n",
      "\n",
      "\u001b[1m-----Datadriven government: Crosscase comparison of data stewardship in data ecosystems  -----\u001b[0m\n",
      "\n",
      "\n",
      "Government agencies are becoming more data-driven and need high-quality data to fulfill their roles in society. In the past, each agency organized its own data exchange system according to its own needs. Today, data is distributed over many organizations, and government agencies need to adopt an ecosystem approach for data exchange. Fundamental in the ecosystem approach is the dependence on other parties for the execution of stewardship strategies. Data-driven government agencies increasingly depend on other organizations for high-quality data and data stewardship across organizations is becoming more critical. While there is ample research on data stewardship within organizations, little is known about data stewardship in ecosystems. More specifically, it is unclear which data stewardship strategies government agencies can employ in ecosystems. The main goal of this explorative paper is to identify and compare data stewardship strategies used in empirical government-business ecosystems. Following an explorative case study approach, this paper reveals three different configurations of inter-organizational data stewardship: 1) the government-led ecosystem, 2) the government-business-led ecosystem, and 3) the regulation-led ecosystem. The case studies expose a wide array of data stewardship strategies across ecosystems. While the ecosystem approach provides advantages such as cost-sharing and innovation by private parties, government agencies become increasingly dependent on private parties to gain high-quality data and provide distributed infrastructure components. Maximizing the benefits and minimizing the risks of the ecosystem approach requires government agencies to be cautious when selecting a specific ecosystem configuration.\n",
      "\n",
      "\n",
      "\u001b[1m-----Government interorganizational, digital transformation projects: five key lessons learned from a Norwegian case study  -----\u001b[0m\n",
      "\n",
      "\n",
      "The purpose of this paper is to gain knowledge about how to manage digital transformation projects in a government context. We analyze a government digital transformation project from its initiation to its end and reflect upon the process and the outcome. The case project did not achieve its intended objectives and therefore provided us with insights on contextual factors and decisions made that contributed to its failure. The results are presented as five key lessons learned. The lessons learned from the case study show that extensive focus on the technology, and selecting, and introducing the digital enabler, might have overshadowed other important concerns, such as early involvement of important stakeholder groups, and implementation of suitable technological platforms that would be fit for purpose to achieve the intended benefits for various stakeholder groups. Even though the intended e-services were not delivered as planned, the project organization learned a lot: in collaborating with government agencies representing different sectors, handling demanding financing schemes across sectors, and making decisions in a project regime that lacked sufficient governance structures.\n"
     ]
    }
   ],
   "source": [
    "titles = list(Summarize.text_dict.keys())\n",
    "for title in titles:\n",
    "    print(\"\\n\")\n",
    "    print(\"\\033[1m\" + f\"-----{title}-----\" + \"\\033[0m\")\n",
    "    print(\"\\n\")\n",
    "    print(Summarize.text_dict[title])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.sciencedirect.com/science/article/pii/S0740624X21001015',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0740624X21000915',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S074301672200002X',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0268401221001237',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0040162521005357',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0313592621000874',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0268401221000797',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0306437921000922',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0740624X21000253',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0740624X2100037X',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0956053X21005717',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0740624X2100099X',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0305750X2030468X',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0167404821002947',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0040162521000299',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0740624X21001003',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0740624X21000800',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0164070421000896',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0740624X21000095',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0740624X22000089',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0264275122000233',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0268401219317141',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S009913332200012X',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S0740624X21000782',\n",
       " 'https://www.sciencedirect.com/science/article/pii/S1877050921023152']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Summarize.urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
